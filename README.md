# Mapreduce TF-IDF

_Implementations of TFIDF mapreduce algorithm using Spark and Hadoop streaming._

Consider the problem of calculating the TF-IDF score for each word in a set of documents
for each document. Provide a MapReduce algorithm to calculate TF-IDF scores given an input set
of documents. Provide both a MapReduce Python Hadoop streaming and a Spark implementation.
Perform experimental analysis in order to compare performances of the two implementation. To
test scalability consider 5 document sets of increasing sizes. For instance, size can double from a
set to another.

The set of input textual document can be either dowloaded from the Web or generated by a Python
script for instance. To speed up document generation MapReduce can be used, for instance by
requiring that n Reducers generate a certain amount of documents each. Words of documents can
be randomly picked from an input fixed vocabulary. Also, you can use Spark to make document
generation easier.
